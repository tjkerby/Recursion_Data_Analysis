{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27bffc09-27a1-4bf3-8c50-48e6fd93a290",
   "metadata": {},
   "source": [
    "# 6 channel data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aedc072-6cb4-424b-a713-c68eefa1ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as D\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "from torchvision import models\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "\n",
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "free_gpu_cache()   \n",
    "\n",
    "\n",
    "# Change the path!\n",
    "path_data = 'D:\\\\Data\\\\DeepLearning\\\\recursion-cellular-image-classification'\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ba0e48-6cbb-418c-b058-fdab61b67b2c",
   "metadata": {},
   "source": [
    "## Dataset thing that will get 6 channels and also the validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf405f-e749-4ba6-a3af-ade90573b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagesDS(D.Dataset):\n",
    "    def __init__(self, df, img_dir, mode='train', site=1, channels=[1,2,3,4,5,6], transform=None):\n",
    "        self.records = df.to_records(index=False)\n",
    "        self.channels = channels\n",
    "        # self.site = site\n",
    "        self.mode = mode\n",
    "        self.img_dir = img_dir\n",
    "        self.len = df.shape[0]\n",
    "        self.transform = transform\n",
    "        self.unique_list = np.unique([int(n.split(\"_\")[1]) for n in df['sirna']])\n",
    "        self.mapping = {}\n",
    "        for (i, val) in enumerate(self.unique_list):\n",
    "            self.mapping[val] = i\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_img_as_tensor(file_name):\n",
    "        with Image.open(file_name) as img:\n",
    "            return T.ToTensor()(img)\n",
    "\n",
    "    def _get_img_path(self, index, channel):\n",
    "        mode = self.mode\n",
    "        if self.mode == 'valid':\n",
    "            mode = 'train'\n",
    "        experiment, well, plate = self.records[index].experiment, self.records[index].well, self.records[index].plate\n",
    "        site = self.records[index].site\n",
    "        return '/'.join([self.img_dir,mode,experiment,f'Plate{plate}',f'{well}_s{site}_w{channel}.png'])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        skip = False\n",
    "        paths_1 = [self._get_img_path(index, ch) for ch in self.channels]\n",
    "        img_1 = []\n",
    "        for img_path in paths_1:\n",
    "            if Path(img_path).exists():\n",
    "                img_1.append(self._load_img_as_tensor(img_path))\n",
    "            else:\n",
    "                img_1.append(torch.zeros(1, 512, 512))\n",
    "        img = torch.cat(img_1)\n",
    "        if self.mode == 'train':\n",
    "            # if training, then apply transformation\n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "            return img, self.mapping[int(self.records[index].sirna.split(\"_\")[1])]\n",
    "        elif self.mode == 'valid':\n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "            return img, self.mapping[int(self.records[index].sirna.split('_')[1])]\n",
    "        else:\n",
    "            return img, self.records[index].id_code\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c199c28-f234-4168-87ad-259046b5d87c",
   "metadata": {},
   "source": [
    "## Creates the data frames for use with 2 sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28db6a42-9eca-4127-aec9-ffa66a31bad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = T.Compose([\n",
    "    T.RandomCrop(384, 384),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(90),\n",
    "    T.RandomVerticalFlip()\n",
    "])\n",
    "\n",
    "\n",
    "df = pd.read_csv(path_data+'/train.csv')\n",
    "df[\"label\"] = -1\n",
    "for index, obs in df.iterrows():\n",
    "    df['label'].loc[index] = int(obs['sirna'].split(\"_\")[1])\n",
    "subset_index = df['label'] <= 1108\n",
    "subset_df = df.loc[subset_index, :]\n",
    "subset_df = subset_df.drop(['label'], axis = 1)\n",
    "subset_df['site'] = \"1\"\n",
    "site_2 = subset_df.copy()\n",
    "site_2['site'] = \"2\"\n",
    "subset_df = pd.concat([subset_df, site_2])\n",
    "\n",
    "print(subset_df)\n",
    "\n",
    "df_train, df_test = train_test_split(subset_df, test_size = 0.1, random_state=42)\n",
    "df_train, df_val = train_test_split(df_train, test_size=0.1, random_state=42)\n",
    "\n",
    "print(df_train)\n",
    "\n",
    "ds_train = ImagesDS(df_train, path_data, mode='train', transform=transforms)\n",
    "ds_val = ImagesDS(df_val, path_data, mode='valid')\n",
    "ds_test = ImagesDS(df_test, path_data, mode='valid')\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_loader = D.DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = D.DataLoader(ds_test, batch_size=batch_size, shuffle=False)\n",
    "valid_loader = D.DataLoader(ds_val, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc9b0ae-7b8e-47b1-a8f5-27986f17c9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_accuracy(model, valid_loader, p=False):\n",
    "    total_t=0\n",
    "    correct_t=0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch_idx, (data_t, target_t) in enumerate(tqdm(valid_loader, desc='Batches', leave=False)):\n",
    "            data_t, target_t = data_t.to(device), target_t.to(device)\n",
    "            outputs_t = model(data_t)\n",
    "            loss_t = criterion(outputs_t, target_t)\n",
    "            _,pred_t = torch.max(outputs_t, dim=1)\n",
    "            correct_t += torch.sum(pred_t==target_t).item()\n",
    "            total_t += target_t.size(0)\n",
    "    return (100 * correct_t / total_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a6b443-b13b-4f42-87bf-84988e2a66c5",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b332ffdb-e447-4a90-95d1-03be22df517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Device is: {device}\")\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "channels = 6\n",
    "trained_kernel = model.conv1.weight\n",
    "new_conv = nn.Conv2d(channels, 64, 7, 2, 3, bias=False)\n",
    "with torch.no_grad():\n",
    "    new_conv.weight[:,:] = torch.stack([torch.mean(trained_kernel, 1)] * channels, dim=1)\n",
    "model.conv1 = new_conv\n",
    "\n",
    "\n",
    "### Load model\n",
    "model.load_state_dict(torch.load(f'6chResNet50/resnet_100.pt'), strict=False)\n",
    "model.eval()\n",
    "\n",
    "classes = 1108\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(model.fc.in_features, 1000),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(1000, classes)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00025)\n",
    "\n",
    "def accuracy(out, labels):\n",
    "    _,pred = torch.max(out, dim=1)\n",
    "    return torch.sum(pred==labels).item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cb9f59-1289-4175-aec1-4913ca128c5d",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66bad2f-91ab-4a30-b33f-7b41c9c75d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to save the best model\n",
    "best_model_path = '6chResNet50/resnet_1108.pt'\n",
    "\n",
    "\n",
    "# If you want a variable batch size, where large_batch is for warm-up\n",
    "large_batch = 64\n",
    "small_batch = 20\n",
    "\n",
    "n_epochs = 200\n",
    "max_val_acc = 0\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "total_step = len(train_loader)\n",
    "for epoch in trange(n_epochs, desc='Epochs', leave=False):\n",
    "    if epoch == 0:\n",
    "        # Sets batch size to the large when only training a few layers\n",
    "        train_loader = D.DataLoader(ds_train, batch_size=large_batch, shuffle=True)\n",
    "        for name, child in model.named_children():\n",
    "            if name == 'fc':\n",
    "                # print(f\"{name} is unfrozen\")\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = True\n",
    "            else:\n",
    "                # print(f\"{name} is frozen\")\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = False\n",
    "    if epoch == 0:\n",
    "        # Shrinks the batch size when training all layers\n",
    "        train_loader = D.DataLoader(ds_train, batch_size=small_batch, shuffle=True)\n",
    "        print(\"Turn on all the layers\")\n",
    "        for name, child in model.named_children():\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = True\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total=0\n",
    "    for batch_idx, (data_, target_) in enumerate(tqdm(train_loader, desc='Batches', leave=False)):\n",
    "        data_, target_ = data_.to(device), target_.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(data_)\n",
    "        loss = criterion(outputs, target_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _,pred = torch.max(outputs, dim=1)\n",
    "        correct += torch.sum(pred==target_).item()\n",
    "        total += target_.size(0)\n",
    "\n",
    "    train_acc.append(100 * correct / total)\n",
    "    train_loss.append(running_loss/total_step)\n",
    "    print(f'train-loss: {np.mean(train_loss):.4f}, train-acc: {(100 * correct/total):.4f}')\n",
    "    batch_loss = 0\n",
    "    total_t=0\n",
    "    correct_t=0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data_t, target_t in valid_loader:\n",
    "            data_t, target_t = data_t.to(device), target_t.to(device)\n",
    "            outputs_t = model(data_t)\n",
    "            loss_t = criterion(outputs_t, target_t)\n",
    "            batch_loss += loss_t.item()\n",
    "            _,pred_t = torch.max(outputs_t, dim=1)\n",
    "            correct_t += torch.sum(pred_t==target_t).item()\n",
    "            total_t += target_t.size(0)\n",
    "        val_acc.append(100 * correct_t/total_t)\n",
    "        val_loss.append(batch_loss/len(valid_loader))\n",
    "        network_learned = val_acc[len(val_acc) - 1] > max_val_acc\n",
    "        print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t/total_t):.4f}')\n",
    "  \n",
    "        if network_learned:\n",
    "            max_val_acc = val_acc[len(val_acc) - 1]\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print('Improvement-Detected, save-model')\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028e05a8-5907-4e83-8247-94fb95246eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model data, will need to change path\n",
    "torch.save(model.state_dict(), f'6chResNet50/resnet_50_1108.pt')\n",
    "torch.save(val_loss, f'6chResNet50acc/val_loss_1108.pt')\n",
    "torch.save(train_loss, f'6chResNet50acc/train_loss_1108.pt')\n",
    "torch.save(val_acc, f'6chResNet50acc/val_acc_1108.pt')\n",
    "torch.save(train_acc, f'6chResNet50acc/train_acc_1108.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7b4a19-af7e-4c6a-8c61-db7d10c82c55",
   "metadata": {},
   "source": [
    "## Load saved model before the next step!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64190502-40a4-451b-96ab-84c852ded6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Device is: {device}\")\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "channels = 6\n",
    "trained_kernel = model.conv1.weight\n",
    "new_conv = nn.Conv2d(channels, 64, 7, 2, 3, bias=False)\n",
    "with torch.no_grad():\n",
    "    new_conv.weight[:,:] = torch.stack([torch.mean(trained_kernel, 1)] * channels, dim=1)\n",
    "model.conv1 = new_conv\n",
    "\n",
    "classes = 1108\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(model.fc.in_features, 1000),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(1000, classes)\n",
    ")\n",
    "\n",
    "### Load model\n",
    "model.load_state_dict(torch.load(f'6chResNet50/resnet_50_1108.pt'), strict=False)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00025)\n",
    "\n",
    "def accuracy(out, labels):\n",
    "    _,pred = torch.max(out, dim=1)\n",
    "    return torch.sum(pred==labels).item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6c3f74-909a-4b50-8577-bffd0c8a7ae2",
   "metadata": {},
   "source": [
    "## Get model accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e652799-a663-4fc9-abbd-938e6184c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = validation_accuracy(model, train_loader, True)\n",
    "valid_accuracy = validation_accuracy(model, valid_loader, True)\n",
    "test_accuracy = validation_accuracy(model, test_loader, True)\n",
    "\n",
    "print(f'Train Accuracy: \\nValidation Accuracy: {valid_accuracy}\\nTest Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095d95a4-cedc-4d8a-97bb-1d7975751bd1",
   "metadata": {},
   "source": [
    "## Make plots if you have saved the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad3b5ed-843c-45a2-a4d7-16e6e31774f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numbers(ch, name, versions) :\n",
    "    res = np.array([])\n",
    "    for v in versions:\n",
    "        temp = torch.load(f'{ch}chResNet50acc/{name}_{v}.pt')\n",
    "        res = np.concatenate((res, np.array(temp)))\n",
    "    return res\n",
    "\n",
    "def get_breaks(ch, name, versions):\n",
    "    res = np.array([])\n",
    "    total = 0\n",
    "    for v in versions:\n",
    "        temp = torch.load(f'{ch}chResNet50acc/{name}_{v}.pt')\n",
    "        total += len(temp)\n",
    "        res = np.concatenate((res, np.array([total])))\n",
    "    return res\n",
    "\n",
    "# Specify what ever version numbers you have saved, like [1,2,3,4]\n",
    "versions = [1108]\n",
    "ch = 6\n",
    "val_loss = get_numbers(ch, 'val_loss', versions)\n",
    "train_loss = get_numbers(ch, 'train_loss', versions)\n",
    "val_acc = get_numbers(ch, 'val_acc', versions)\n",
    "train_acc = get_numbers(ch, 'train_acc', versions)\n",
    "breaks = get_breaks(ch, 'val_loss', versions)\n",
    "breaks = np.delete(breaks, -1)\n",
    "\n",
    "plt.plot(train_loss, color=\"blue\", label='Training')\n",
    "plt.plot(val_loss, color=\"orange\", label='Validation')\n",
    "plt.legend()\n",
    "for xc in breaks:\n",
    "    plt.axvline(x = xc, alpha=0.5)\n",
    "plt.title(f\"1108 Classes {ch}ch ResNet50 Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_acc, color=\"blue\", label='Training')\n",
    "plt.plot(val_acc, color=\"orange\", label='Validation')\n",
    "# Change this \n",
    "plt.axhline(y=test_accuracy, c='green', linestyle='dashed', label='Final Test', alpha = .45)\n",
    "plt.legend()\n",
    "for xc in breaks:\n",
    "    plt.axvline(x = xc, alpha=0.5)\n",
    "plt.title(f\"1108 Classes {ch}ch ResNet50 Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy %\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Before this, you should have downloaded and unzipped all the data from kaggle.\n",
    "Be sure to update your working directory to get the data all formatted.\n",
    "\n",
    "This is directly from https://www.kaggle.com/yhn112/resnet18-baseline-pytorch-ignite/notebook"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.utils.data as D\n",
    "from torchvision import models, transforms as T\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Be sure to update path_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x2029bc49890>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data = 'D:\\\\Data\\\\DeepLearning\\\\recursion-cellular-image-classification'\n",
    "device = 'cuda'\n",
    "batch_size = 32\n",
    "torch.manual_seed(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class ImagesDS(D.Dataset):\n",
    "    def __init__(self, df, img_dir, mode='train', site=1, channels=[1,2,3,4,5,6]):\n",
    "        self.records = df.to_records(index=False)\n",
    "        self.channels = channels\n",
    "        self.site = site\n",
    "        self.mode = mode\n",
    "        self.img_dir = img_dir\n",
    "        self.len = df.shape[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_img_as_tensor(file_name):\n",
    "        with Image.open(file_name) as img:\n",
    "            return T.ToTensor()(img)\n",
    "\n",
    "    def _get_img_path(self, index, channel):\n",
    "        experiment, well, plate = self.records[index].experiment, self.records[index].well, self.records[index].plate\n",
    "        return '/'.join([self.img_dir,self.mode,experiment,f'Plate{plate}',f'{well}_s{self.site}_w{channel}.png'])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        paths = [self._get_img_path(index, ch) for ch in self.channels]\n",
    "        img = torch.cat([self._load_img_as_tensor(img_path) for img_path in paths])\n",
    "        if self.mode == 'train':\n",
    "            return img, int(self.records[index].sirna)\n",
    "        else:\n",
    "            return img, self.records[index].id_code\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_data+'/train.csv')\n",
    "df_train, df_val = train_test_split(df, test_size = 0.025, random_state=42)\n",
    "df_test = pd.read_csv(path_data+'/test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "ds = ImagesDS(df_train, path_data, mode='train')\n",
    "ds_val = ImagesDS(df_val, path_data, mode='train')\n",
    "ds_test = ImagesDS(df_test, path_data, mode='test')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Before this, you should have downloaded and unzipped all the data from kaggle.\n",
    "Be sure to update your working directory to get the data all formatted.\n",
    "\n",
    "This is directly from https://www.kaggle.com/yhn112/resnet18-baseline-pytorch-ignite/notebook"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as D\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "from torchvision import models\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Be sure to update path_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x180b9ce3310>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data = 'D:\\\\Data\\\\DeepLearning\\\\recursion-cellular-image-classification'\n",
    "batch_size = 32\n",
    "torch.manual_seed(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "class ImagesDS(D.Dataset):\n",
    "    def __init__(self, df, img_dir, mode='train', site=1, channels=[1,2,3,4,5,6], transform=None):\n",
    "        self.records = df.to_records(index=False)\n",
    "        self.channels = channels\n",
    "        # self.site = site\n",
    "        self.mode = mode\n",
    "        self.img_dir = img_dir\n",
    "        self.len = df.shape[0]\n",
    "        self.transform = transform\n",
    "        unique_list = np.unique([int(n.split(\"_\")[1]) for n in df['sirna']])\n",
    "        self.mapping = {}\n",
    "        for (i, val) in enumerate(unique_list):\n",
    "            self.mapping[val] = i\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_img_as_tensor(file_name):\n",
    "        with Image.open(file_name) as img:\n",
    "            return T.ToTensor()(img)\n",
    "\n",
    "    def _get_img_path(self, index, channel, site):\n",
    "        mode = self.mode\n",
    "        if self.mode == 'valid':\n",
    "            mode = 'train'\n",
    "        experiment, well, plate = self.records[index].experiment, self.records[index].well, self.records[index].plate\n",
    "        return '/'.join([self.img_dir,mode,experiment,f'Plate{plate}',f'{well}_s{site}_w{channel}.png'])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        paths_1 = [self._get_img_path(index, ch, 1) for ch in self.channels]\n",
    "        paths_2 = [self._get_img_path(index, ch, 2) for ch in self.channels]\n",
    "        img_1 = torch.cat([self._load_img_as_tensor(img_path) for img_path in paths_1])\n",
    "        img_2 = torch.cat([self._load_img_as_tensor(img_path) for img_path in paths_2])\n",
    "        img = torch.cat([img_1, img_2])\n",
    "        if self.mode == 'train':\n",
    "            # if training, then apply transformation\n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "            return img, self.mapping[int(self.records[index].sirna.split(\"_\")[1])]\n",
    "        elif self.mode == 'valid':\n",
    "            return img, self.mapping[int(self.records[index].sirna.split('_')[1])]\n",
    "        else:\n",
    "            return img, self.records[index].id_code\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define transformations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "transforms = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(90),\n",
    "    T.RandomVerticalFlip()\n",
    "])\n",
    "\n",
    "# transforms = T.Compose([\n",
    "#     T.Resize((224,224)),\n",
    "#     T.CenterCrop(224),\n",
    "#     # T.ToTensor(),\n",
    "#     T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     T.RandomHorizontalFlip(),\n",
    "#     T.RandomRotation(90),\n",
    "#     T.RandomVerticalFlip()\n",
    "# ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Gets data from site 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_data+'/train.csv')\n",
    "df_train, df_test = train_test_split(df, test_size = 0.1, random_state=42)\n",
    "df_train, df_val = train_test_split(df_train, test_size=.01, random_state=42)\n",
    "# df_test = pd.read_csv(path_data+'/test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "ds_train = ImagesDS(df_train, path_data, mode='train', transform=transforms)\n",
    "ds_val = ImagesDS(df_val, path_data, mode='valid')\n",
    "ds_test = ImagesDS(df_test, path_data, mode='test')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "{0: 0,\n 1: 1,\n 2: 2,\n 3: 3,\n 4: 4,\n 5: 5,\n 6: 6,\n 7: 7,\n 8: 8,\n 9: 9,\n 10: 10,\n 11: 11,\n 12: 12,\n 13: 13,\n 14: 14,\n 15: 15,\n 16: 16,\n 17: 17,\n 18: 18,\n 19: 19,\n 20: 20,\n 21: 21,\n 22: 22,\n 23: 23,\n 24: 24,\n 25: 25,\n 26: 26,\n 27: 27,\n 28: 28,\n 29: 29,\n 30: 30,\n 31: 31,\n 32: 32,\n 33: 33,\n 34: 34,\n 35: 35,\n 36: 36,\n 37: 37,\n 38: 38,\n 39: 39,\n 40: 40,\n 41: 41,\n 42: 42,\n 43: 43,\n 44: 44,\n 45: 45,\n 46: 46,\n 47: 47,\n 48: 48,\n 49: 49,\n 50: 50,\n 51: 51,\n 53: 52,\n 54: 53,\n 55: 54,\n 56: 55,\n 57: 56,\n 58: 57,\n 59: 58,\n 60: 59,\n 61: 60,\n 62: 61,\n 63: 62,\n 64: 63,\n 65: 64,\n 66: 65,\n 67: 66,\n 68: 67,\n 69: 68,\n 70: 69,\n 71: 70,\n 72: 71,\n 73: 72,\n 74: 73,\n 75: 74,\n 76: 75,\n 77: 76,\n 78: 77,\n 79: 78,\n 80: 79,\n 81: 80,\n 82: 81,\n 83: 82,\n 84: 83,\n 85: 84,\n 86: 85,\n 87: 86,\n 88: 87,\n 89: 88,\n 90: 89,\n 91: 90,\n 92: 91,\n 93: 92,\n 94: 93,\n 95: 94,\n 96: 95,\n 97: 96,\n 98: 97,\n 99: 98,\n 100: 99,\n 101: 100,\n 102: 101,\n 103: 102,\n 104: 103,\n 105: 104,\n 106: 105,\n 107: 106,\n 108: 107,\n 109: 108,\n 110: 109,\n 111: 110,\n 112: 111,\n 113: 112,\n 114: 113,\n 115: 114,\n 116: 115,\n 117: 116,\n 118: 117,\n 119: 118,\n 120: 119,\n 121: 120,\n 122: 121,\n 123: 122,\n 124: 123,\n 125: 124,\n 126: 125,\n 127: 126,\n 128: 127,\n 129: 128,\n 130: 129,\n 131: 130,\n 132: 131,\n 133: 132,\n 134: 133,\n 135: 134,\n 136: 135,\n 137: 136,\n 138: 137,\n 139: 138,\n 140: 139,\n 141: 140,\n 142: 141,\n 143: 142,\n 145: 143,\n 146: 144,\n 147: 145,\n 148: 146,\n 149: 147,\n 150: 148,\n 151: 149,\n 152: 150,\n 153: 151,\n 154: 152,\n 155: 153,\n 156: 154,\n 157: 155,\n 158: 156,\n 159: 157,\n 160: 158,\n 161: 159,\n 162: 160,\n 163: 161,\n 164: 162,\n 165: 163,\n 166: 164,\n 167: 165,\n 168: 166,\n 169: 167,\n 170: 168,\n 171: 169,\n 172: 170,\n 173: 171,\n 174: 172,\n 175: 173,\n 176: 174,\n 177: 175,\n 178: 176,\n 179: 177,\n 180: 178,\n 181: 179,\n 182: 180,\n 183: 181,\n 184: 182,\n 185: 183,\n 186: 184,\n 187: 185,\n 188: 186,\n 189: 187,\n 190: 188,\n 191: 189,\n 192: 190,\n 193: 191,\n 194: 192,\n 195: 193,\n 196: 194,\n 197: 195,\n 198: 196,\n 199: 197,\n 200: 198,\n 202: 199,\n 203: 200,\n 204: 201,\n 205: 202,\n 206: 203,\n 207: 204,\n 208: 205,\n 209: 206,\n 210: 207,\n 211: 208,\n 212: 209,\n 213: 210,\n 214: 211,\n 215: 212,\n 216: 213,\n 217: 214,\n 218: 215,\n 219: 216,\n 220: 217,\n 221: 218,\n 222: 219,\n 223: 220,\n 224: 221,\n 225: 222,\n 226: 223,\n 227: 224,\n 228: 225,\n 229: 226,\n 230: 227,\n 231: 228,\n 232: 229,\n 233: 230,\n 234: 231,\n 235: 232,\n 236: 233,\n 238: 234,\n 239: 235,\n 240: 236,\n 241: 237,\n 242: 238,\n 243: 239,\n 244: 240,\n 245: 241,\n 246: 242,\n 247: 243,\n 248: 244,\n 249: 245,\n 250: 246,\n 251: 247,\n 252: 248,\n 253: 249,\n 254: 250,\n 255: 251,\n 257: 252,\n 258: 253,\n 259: 254,\n 260: 255,\n 261: 256,\n 262: 257,\n 263: 258,\n 264: 259,\n 265: 260,\n 266: 261,\n 267: 262,\n 268: 263,\n 269: 264,\n 270: 265,\n 271: 266,\n 273: 267,\n 274: 268,\n 275: 269,\n 276: 270,\n 277: 271,\n 278: 272,\n 279: 273,\n 280: 274,\n 281: 275,\n 282: 276,\n 283: 277,\n 284: 278,\n 285: 279,\n 286: 280,\n 287: 281,\n 288: 282,\n 289: 283,\n 290: 284,\n 291: 285,\n 292: 286,\n 293: 287,\n 294: 288,\n 295: 289,\n 296: 290,\n 297: 291,\n 298: 292,\n 299: 293,\n 300: 294,\n 301: 295,\n 302: 296,\n 303: 297,\n 304: 298,\n 305: 299,\n 306: 300,\n 307: 301,\n 308: 302,\n 309: 303,\n 310: 304,\n 311: 305,\n 312: 306,\n 313: 307,\n 314: 308,\n 315: 309,\n 316: 310,\n 317: 311,\n 318: 312,\n 319: 313,\n 320: 314,\n 321: 315,\n 322: 316,\n 324: 317,\n 325: 318,\n 326: 319,\n 327: 320,\n 328: 321,\n 329: 322,\n 330: 323,\n 331: 324,\n 332: 325,\n 333: 326,\n 334: 327,\n 335: 328,\n 336: 329,\n 337: 330,\n 338: 331,\n 339: 332,\n 340: 333,\n 341: 334,\n 342: 335,\n 343: 336,\n 344: 337,\n 345: 338,\n 346: 339,\n 347: 340,\n 348: 341,\n 349: 342,\n 350: 343,\n 351: 344,\n 352: 345,\n 353: 346,\n 354: 347,\n 355: 348,\n 356: 349,\n 357: 350,\n 358: 351,\n 359: 352,\n 360: 353,\n 361: 354,\n 362: 355,\n 363: 356,\n 364: 357,\n 365: 358,\n 366: 359,\n 367: 360,\n 368: 361,\n 369: 362,\n 370: 363,\n 371: 364,\n 372: 365,\n 373: 366,\n 375: 367,\n 376: 368,\n 377: 369,\n 378: 370,\n 379: 371,\n 380: 372,\n 381: 373,\n 382: 374,\n 383: 375,\n 384: 376,\n 385: 377,\n 386: 378,\n 387: 379,\n 388: 380,\n 389: 381,\n 390: 382,\n 391: 383,\n 392: 384,\n 393: 385,\n 394: 386,\n 395: 387,\n 396: 388,\n 397: 389,\n 398: 390,\n 399: 391,\n 400: 392,\n 401: 393,\n 402: 394,\n 403: 395,\n 404: 396,\n 405: 397,\n 406: 398,\n 407: 399,\n 408: 400,\n 409: 401,\n 411: 402,\n 412: 403,\n 413: 404,\n 414: 405,\n 415: 406,\n 416: 407,\n 417: 408,\n 418: 409,\n 419: 410,\n 420: 411,\n 421: 412,\n 422: 413,\n 423: 414,\n 424: 415,\n 425: 416,\n 426: 417,\n 427: 418,\n 428: 419,\n 429: 420,\n 430: 421,\n 431: 422,\n 432: 423,\n 433: 424,\n 434: 425,\n 435: 426,\n 436: 427,\n 437: 428,\n 438: 429,\n 439: 430,\n 440: 431,\n 441: 432,\n 442: 433,\n 443: 434,\n 444: 435,\n 445: 436,\n 446: 437,\n 447: 438,\n 448: 439,\n 449: 440,\n 450: 441,\n 451: 442,\n 452: 443,\n 453: 444,\n 454: 445,\n 455: 446,\n 456: 447,\n 457: 448,\n 458: 449,\n 459: 450,\n 460: 451,\n 461: 452,\n 462: 453,\n 463: 454,\n 464: 455,\n 465: 456,\n 466: 457,\n 467: 458,\n 468: 459,\n 469: 460,\n 470: 461,\n 471: 462,\n 472: 463,\n 473: 464,\n 474: 465,\n 475: 466,\n 476: 467,\n 477: 468,\n 478: 469,\n 479: 470,\n 480: 471,\n 481: 472,\n 482: 473,\n 483: 474,\n 484: 475,\n 485: 476,\n 486: 477,\n 487: 478,\n 488: 479,\n 489: 480,\n 490: 481,\n 491: 482,\n 492: 483,\n 493: 484,\n 494: 485,\n 495: 486,\n 496: 487,\n 497: 488,\n 498: 489,\n 499: 490,\n 500: 491,\n 501: 492,\n 502: 493,\n 503: 494,\n 504: 495,\n 505: 496,\n 506: 497,\n 507: 498,\n 508: 499,\n 509: 500,\n 510: 501,\n 511: 502,\n 512: 503,\n 513: 504,\n 514: 505,\n 515: 506,\n 516: 507,\n 517: 508,\n 518: 509,\n 519: 510,\n 520: 511,\n 521: 512,\n 522: 513,\n 523: 514,\n 524: 515,\n 525: 516,\n 526: 517,\n 527: 518,\n 528: 519,\n 529: 520,\n 530: 521,\n 531: 522,\n 532: 523,\n 533: 524,\n 534: 525,\n 535: 526,\n 536: 527,\n 537: 528,\n 538: 529,\n 539: 530,\n 540: 531,\n 541: 532,\n 543: 533,\n 544: 534,\n 545: 535,\n 546: 536,\n 547: 537,\n 548: 538,\n 549: 539,\n 550: 540,\n 551: 541,\n 552: 542,\n 553: 543,\n 554: 544,\n 555: 545,\n 556: 546,\n 557: 547,\n 558: 548,\n 559: 549,\n 560: 550,\n 561: 551,\n 562: 552,\n 563: 553,\n 564: 554,\n 565: 555,\n 566: 556,\n 567: 557,\n 568: 558,\n 569: 559,\n 570: 560,\n 571: 561,\n 572: 562,\n 573: 563,\n 574: 564,\n 575: 565,\n 576: 566,\n 578: 567,\n 579: 568,\n 580: 569,\n 581: 570,\n 582: 571,\n 583: 572,\n 584: 573,\n 585: 574,\n 586: 575,\n 587: 576,\n 588: 577,\n 589: 578,\n 590: 579,\n 591: 580,\n 592: 581,\n 593: 582,\n 594: 583,\n 595: 584,\n 596: 585,\n 597: 586,\n 598: 587,\n 599: 588,\n 600: 589,\n 601: 590,\n 602: 591,\n 603: 592,\n 604: 593,\n 605: 594,\n 606: 595,\n 607: 596,\n 608: 597,\n 609: 598,\n 610: 599,\n 611: 600,\n 612: 601,\n 613: 602,\n 614: 603,\n 615: 604,\n 616: 605,\n 617: 606,\n 619: 607,\n 620: 608,\n 621: 609,\n 622: 610,\n 623: 611,\n 624: 612,\n 625: 613,\n 626: 614,\n 627: 615,\n 628: 616,\n 629: 617,\n 630: 618,\n 631: 619,\n 632: 620,\n 633: 621,\n 634: 622,\n 635: 623,\n 636: 624,\n 637: 625,\n 638: 626,\n 639: 627,\n 640: 628,\n 641: 629,\n 642: 630,\n 643: 631,\n 644: 632,\n 645: 633,\n 646: 634,\n 647: 635,\n 648: 636,\n 649: 637,\n 651: 638,\n 652: 639,\n 653: 640,\n 654: 641,\n 655: 642,\n 656: 643,\n 657: 644,\n 658: 645,\n 659: 646,\n 660: 647,\n 661: 648,\n 662: 649,\n 663: 650,\n 664: 651,\n 665: 652,\n 666: 653,\n 667: 654,\n 668: 655,\n 669: 656,\n 670: 657,\n 671: 658,\n 673: 659,\n 674: 660,\n 675: 661,\n 676: 662,\n 677: 663,\n 678: 664,\n 679: 665,\n 680: 666,\n 681: 667,\n 683: 668,\n 684: 669,\n 685: 670,\n 686: 671,\n 687: 672,\n 688: 673,\n 689: 674,\n 690: 675,\n 691: 676,\n 692: 677,\n 693: 678,\n 694: 679,\n 695: 680,\n 696: 681,\n 697: 682,\n 698: 683,\n 699: 684,\n 700: 685,\n 701: 686,\n 703: 687,\n 704: 688,\n 705: 689,\n 706: 690,\n 707: 691,\n 708: 692,\n 709: 693,\n 710: 694,\n 711: 695,\n 712: 696,\n 713: 697,\n 715: 698,\n 716: 699,\n 717: 700,\n 718: 701,\n 719: 702,\n 720: 703,\n 721: 704,\n 722: 705,\n 723: 706,\n 724: 707,\n 725: 708,\n 726: 709,\n 727: 710,\n 728: 711,\n 729: 712,\n 730: 713,\n 731: 714,\n 732: 715,\n 733: 716,\n 734: 717,\n 735: 718,\n 736: 719,\n 737: 720,\n 738: 721,\n 739: 722,\n 740: 723,\n 741: 724,\n 742: 725,\n 743: 726,\n 744: 727,\n 745: 728,\n 746: 729,\n 747: 730,\n 748: 731,\n 749: 732,\n 750: 733,\n 751: 734,\n 752: 735,\n 753: 736,\n 754: 737,\n 755: 738,\n 757: 739,\n 758: 740,\n 759: 741,\n 760: 742,\n 761: 743,\n 762: 744,\n 763: 745,\n 764: 746,\n 765: 747,\n 767: 748,\n 768: 749,\n 769: 750,\n 770: 751,\n 771: 752,\n 772: 753,\n 773: 754,\n 774: 755,\n 775: 756,\n 776: 757,\n 777: 758,\n 778: 759,\n 779: 760,\n 780: 761,\n 781: 762,\n 782: 763,\n 783: 764,\n 784: 765,\n 785: 766,\n 786: 767,\n 787: 768,\n 788: 769,\n 789: 770,\n 790: 771,\n 791: 772,\n 792: 773,\n 793: 774,\n 794: 775,\n 795: 776,\n 796: 777,\n 797: 778,\n 798: 779,\n 799: 780,\n 800: 781,\n 801: 782,\n 802: 783,\n 803: 784,\n 804: 785,\n 805: 786,\n 806: 787,\n 807: 788,\n 808: 789,\n 809: 790,\n 811: 791,\n 812: 792,\n 813: 793,\n 814: 794,\n 815: 795,\n 816: 796,\n 817: 797,\n 818: 798,\n 819: 799,\n 820: 800,\n 821: 801,\n 823: 802,\n 824: 803,\n 826: 804,\n 827: 805,\n 828: 806,\n 829: 807,\n 830: 808,\n 831: 809,\n 832: 810,\n 833: 811,\n 834: 812,\n 835: 813,\n 836: 814,\n 837: 815,\n 838: 816,\n 839: 817,\n 840: 818,\n 841: 819,\n 843: 820,\n 844: 821,\n 845: 822,\n 846: 823,\n 847: 824,\n 848: 825,\n 849: 826,\n 850: 827,\n 851: 828,\n 853: 829,\n 854: 830,\n 855: 831,\n 856: 832,\n 857: 833,\n 858: 834,\n 859: 835,\n 860: 836,\n 861: 837,\n 862: 838,\n 863: 839,\n 865: 840,\n 866: 841,\n 867: 842,\n 868: 843,\n 869: 844,\n 870: 845,\n 871: 846,\n 872: 847,\n 873: 848,\n 874: 849,\n 875: 850,\n 876: 851,\n 877: 852,\n 878: 853,\n 879: 854,\n 880: 855,\n 881: 856,\n 882: 857,\n 883: 858,\n 884: 859,\n 885: 860,\n 886: 861,\n 887: 862,\n 889: 863,\n 890: 864,\n 891: 865,\n 892: 866,\n 893: 867,\n 894: 868,\n 895: 869,\n 896: 870,\n 897: 871,\n 898: 872,\n 899: 873,\n 900: 874,\n 901: 875,\n 902: 876,\n 903: 877,\n 904: 878,\n 905: 879,\n 906: 880,\n 907: 881,\n 908: 882,\n 909: 883,\n 910: 884,\n 911: 885,\n 912: 886,\n 913: 887,\n 914: 888,\n 915: 889,\n 916: 890,\n 917: 891,\n 918: 892,\n 919: 893,\n 920: 894,\n 921: 895,\n 922: 896,\n 923: 897,\n 924: 898,\n 925: 899,\n 926: 900,\n 927: 901,\n 928: 902,\n 929: 903,\n 930: 904,\n 931: 905,\n 932: 906,\n 933: 907,\n 934: 908,\n 935: 909,\n 936: 910,\n 937: 911,\n 938: 912,\n 939: 913,\n 940: 914,\n 941: 915,\n 942: 916,\n 943: 917,\n 944: 918,\n 945: 919,\n 946: 920,\n 947: 921,\n 948: 922,\n 949: 923,\n 950: 924,\n 951: 925,\n 952: 926,\n 953: 927,\n 954: 928,\n 955: 929,\n 956: 930,\n 957: 931,\n 958: 932,\n 959: 933,\n 960: 934,\n 961: 935,\n 962: 936,\n 963: 937,\n 964: 938,\n 965: 939,\n 966: 940,\n 968: 941,\n 969: 942,\n 970: 943,\n 971: 944,\n 972: 945,\n 973: 946,\n 974: 947,\n 975: 948,\n 976: 949,\n 977: 950,\n 978: 951,\n 979: 952,\n 980: 953,\n 981: 954,\n 982: 955,\n 983: 956,\n 984: 957,\n 985: 958,\n 986: 959,\n 987: 960,\n 988: 961,\n 989: 962,\n 990: 963,\n 991: 964,\n 992: 965,\n 993: 966,\n 994: 967,\n 995: 968,\n 996: 969,\n 997: 970,\n 998: 971,\n 999: 972,\n 1000: 973,\n 1001: 974,\n 1002: 975,\n 1003: 976,\n 1004: 977,\n 1005: 978,\n 1006: 979,\n 1007: 980,\n 1008: 981,\n 1009: 982,\n 1010: 983,\n 1012: 984,\n 1013: 985,\n 1014: 986,\n 1015: 987,\n 1016: 988,\n 1017: 989,\n 1018: 990,\n 1019: 991,\n 1020: 992,\n 1021: 993,\n 1022: 994,\n 1023: 995,\n 1024: 996,\n 1025: 997,\n 1026: 998,\n 1027: 999,\n ...}"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creates DataLoader which is what is used for the models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "train_loader = D.DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = D.DataLoader(ds_test, batch_size=batch_size, shuffle=False)\n",
    "valid_loader = D.DataLoader(ds_val, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-23-387572884d8f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mfor\u001B[0m \u001B[0mbatch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtrain_loader\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    519\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sampler_iter\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    520\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 521\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    522\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    523\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[1;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    559\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    560\u001B[0m         \u001B[0mindex\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# may raise StopIteration\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 561\u001B[1;33m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# may raise StopIteration\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    562\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    563\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     48\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 49\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     50\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     51\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     47\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     48\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 49\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     50\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     51\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-18-db6ae4e3a97d>\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m     27\u001B[0m             \u001B[1;31m# if training, then apply transformation\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     28\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 29\u001B[1;33m                 \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     30\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mimg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrecords\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msirna\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"_\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     31\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'valid'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m     59\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mimg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     60\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransforms\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 61\u001B[1;33m             \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     62\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mimg\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1103\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m   1302\u001B[0m         \u001B[0mangle\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_params\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdegrees\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1303\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1304\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrotate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mangle\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresample\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexpand\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcenter\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfill\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1305\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1306\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__repr__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001B[0m in \u001B[0;36mrotate\u001B[1;34m(img, angle, interpolation, expand, center, fill, resample)\u001B[0m\n\u001B[0;32m   1017\u001B[0m     \u001B[1;31m# we need to set -angle.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1018\u001B[0m     \u001B[0mmatrix\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_get_inverse_affine_matrix\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcenter_f\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m-\u001B[0m\u001B[0mangle\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;36m0.0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0.0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1.0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;36m0.0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0.0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1019\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mF_t\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrotate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmatrix\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmatrix\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minterpolation\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minterpolation\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mexpand\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mexpand\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfill\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfill\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1020\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1021\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional_tensor.py\u001B[0m in \u001B[0;36mrotate\u001B[1;34m(img, matrix, interpolation, expand, fill)\u001B[0m\n\u001B[0;32m    736\u001B[0m     \u001B[0mgrid\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_gen_affine_grid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtheta\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mw\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mw\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mh\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mow\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mow\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moh\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0moh\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    737\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 738\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_apply_grid_transform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrid\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minterpolation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfill\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfill\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    739\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    740\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional_tensor.py\u001B[0m in \u001B[0;36m_apply_grid_transform\u001B[1;34m(img, grid, mode, fill)\u001B[0m\n\u001B[0;32m    645\u001B[0m         \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdummy\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    646\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 647\u001B[1;33m     \u001B[0mimg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgrid_sample\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrid\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpadding_mode\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"zeros\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0malign_corners\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    648\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    649\u001B[0m     \u001B[1;31m# Fill with required color\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001B[0m in \u001B[0;36mgrid_sample\u001B[1;34m(input, grid, mode, padding_mode, align_corners)\u001B[0m\n\u001B[0;32m   4009\u001B[0m         \u001B[0malign_corners\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4010\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 4011\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgrid_sampler\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrid\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode_enum\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpadding_mode_enum\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0malign_corners\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   4012\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4013\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Example model training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "device='cpu'\n",
    "\n",
    "classes = 1108\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, classes)\n",
    "\n",
    "trained_kernel = model.conv1.weight\n",
    "new_conv = nn.Conv2d(12, 64, 7, 2, 3, bias=False)\n",
    "with torch.no_grad():\n",
    "    new_conv.weight[:,:] = torch.stack([torch.mean(trained_kernel, 1)] * 12, dim=1)\n",
    "model.conv1 = new_conv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "def validation_accuracy(model, testloader, p=False):\n",
    "    with torch.no_grad(): # In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in testloader:\n",
    "\n",
    "            '''Step - Move images to device after appropriate reshaping'''\n",
    "            images = images.to(device)\n",
    "            '''Step  - Move labels to device'''\n",
    "            labels = labels.to(device)\n",
    "            #get network outputs\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        if p:\n",
    "            print(f'Accuracy of the network on the 10000 test images: {(100 * correct / total)}')\n",
    "        return 100 * correct / total"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<built-in method item of Tensor object at 0x0000018082B539F0>\n",
      "1\n",
      "<built-in method item of Tensor object at 0x0000018082B484A0>\n",
      "2\n",
      "<built-in method item of Tensor object at 0x0000018082B483B0>\n",
      "3\n",
      "<built-in method item of Tensor object at 0x0000018082B48C20>\n",
      "4\n",
      "<built-in method item of Tensor object at 0x0000018082B489F0>\n",
      "5\n",
      "<built-in method item of Tensor object at 0x0000018082B48900>\n",
      "6\n",
      "<built-in method item of Tensor object at 0x0000018082B480E0>\n",
      "7\n",
      "<built-in method item of Tensor object at 0x0000018082B48860>\n",
      "8\n",
      "<built-in method item of Tensor object at 0x0000018082B48D10>\n",
      "9\n",
      "<built-in method item of Tensor object at 0x0000018082B486D0>\n",
      "Epoch [1/1], Step [10/925], Loss: 7.4407\n",
      "10\n",
      "<built-in method item of Tensor object at 0x0000018082B489F0>\n",
      "11\n",
      "<built-in method item of Tensor object at 0x0000018082B484F0>\n",
      "12\n",
      "<built-in method item of Tensor object at 0x0000018082B48040>\n",
      "13\n",
      "<built-in method item of Tensor object at 0x0000018082B48C20>\n",
      "14\n",
      "<built-in method item of Tensor object at 0x0000018082B48310>\n",
      "15\n",
      "<built-in method item of Tensor object at 0x0000018082B48CC0>\n",
      "16\n",
      "<built-in method item of Tensor object at 0x0000018082B487C0>\n",
      "17\n",
      "<built-in method item of Tensor object at 0x0000018082B48D10>\n",
      "18\n",
      "<built-in method item of Tensor object at 0x0000018082B48C20>\n",
      "19\n",
      "<built-in method item of Tensor object at 0x0000018082B48DB0>\n",
      "Epoch [1/1], Step [20/925], Loss: 7.5982\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "Nepochs = 1\n",
    "Nbatch = 20\n",
    "\n",
    "stop = False\n",
    "minimum_loss = .8\n",
    "\n",
    "model.train()\n",
    "model.to(device)\n",
    "for i in range(Nepochs):\n",
    "    if stop:\n",
    "        break\n",
    "    for j, batch in enumerate(train_loader):\n",
    "        print(j)\n",
    "        images, labels = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss.item())\n",
    "        if (j+1) % 10 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                   .format(i+1, Nepochs, j+1, len(train_loader), loss.item()))\n",
    "\n",
    "        Nbatch -= 1\n",
    "        if Nbatch <= 0 or loss <= minimum_loss:\n",
    "            stop = True\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 0.303951367781155\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.303951367781155"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_accuracy(model, valid_loader, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}